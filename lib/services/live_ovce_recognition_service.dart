import 'dart:ui';
import 'package:camera/camera.dart';
import 'package:flutter/foundation.dart';
import 'package:google_mlkit_face_detection/google_mlkit_face_detection.dart';
import 'package:google_mlkit_object_detection/google_mlkit_object_detection.dart';
import 'package:google_mlkit_text_recognition/google_mlkit_text_recognition.dart';
import '../models/ovce.dart';
import '../models/ovce_biometrics.dart';
import 'ovce_service.dart';
import 'biometric_extraction_service.dart';

/// V√Ωsledek rozpozn√°n√≠ ovce na live videu
class OvceMatch {
  final Ovce ovce;
  final double confidence; // 0.0 - 1.0
  final Rect boundingBox; // Pozice na obrazovce
  
  OvceMatch({
    required this.ovce,
    required this.confidence,
    required this.boundingBox,
  });
}

/// Servis pro live rozpozn√°v√°n√≠ ovc√≠ v kamerov√©m n√°hledu
class LiveOvceRecognitionService {
  final FaceDetector _faceDetector = FaceDetector(
    options: FaceDetectorOptions(
      enableContours: true,
      enableClassification: true,
      enableLandmarks: true,
      enableTracking: true,
    ),
  );
  
  final ObjectDetector _objectDetector = ObjectDetector(
    options: ObjectDetectorOptions(
      mode: DetectionMode.stream,
      classifyObjects: true,
      multipleObjects: true,
    ),
  );

  final TextRecognizer _textRecognizer = TextRecognizer();

  final OvceService _ovceService = OvceService();
  final BiometricExtractionService _biometricExtractor = BiometricExtractionService();
  List<Ovce> _referenceOvce = []; // Seznam ovc√≠ z datab√°ze
  
  /// Inicializuje servis a naƒçte referenƒçn√≠ ovce
  Future<void> initialize() async {
    _referenceOvce = _ovceService.getAllOvce();
    print('üêë Naƒçteno ${_referenceOvce.length} referenƒçn√≠ch ovc√≠ pro rozpozn√°v√°n√≠');
    
    // Filtrace ovc√≠ s biometrick√Ωmi daty
    final trainedOvce = _referenceOvce.where((ovce) => ovce.hasGoodBiometrics).toList();
    print('üéØ ${trainedOvce.length} ovc√≠ m√° kvalitn√≠ biometrick√° data pro rozpozn√°v√°n√≠');
  }
  
  /// Nastav√≠ referenƒçn√≠ ovce pro porovn√°n√≠
  void setReferenceOvce(List<Ovce> ovce) {
    _referenceOvce = ovce;
    print('üêë Nastaveno ${ovce.length} referenƒçn√≠ch ovc√≠ pro rozpozn√°v√°n√≠');
  }

  /// Rozpozn√° ovce na live video frame
  Future<List<OvceMatch>> recognizeOvceInFrame(CameraImage image) async {
    try {
      final inputImage = _convertCameraImage(image);
      if (inputImage == null) return [];

      print('üìπ Analyzuji frame ${image.width}x${image.height}');

      // 1. Detekce textu (u≈°n√≠ znaƒçky)
      final recognizedText = await _textRecognizer.processImage(inputImage);
      final textMatches = await _matchTextToOvce(recognizedText);

      // 2. Detekce obliƒçej≈Ø (funguje i na zv√≠≈ôata)
      final faces = await _faceDetector.processImage(inputImage);
      print('üë§ Nalezeno ${faces.length} obliƒçej≈Ø/hlav');

      // 3. Detekce obecn√Ωch objekt≈Ø
      final objects = await _objectDetector.processImage(inputImage);
      print('üéØ Nalezeno ${objects.length} objekt≈Ø');

      // 4. Kombinujeme v√Ωsledky a porovn√°v√°me s datab√°z√≠
      final matches = <OvceMatch>[];
      
      // Priorita: Text > Obliƒçeje > Objekty
      matches.addAll(textMatches);
      
      // Pro ka≈æd√Ω nalezen√Ω obliƒçej/hlavu
      for (final face in faces) {
        final match = await _matchFaceToOvce(face, image);
        if (match != null) {
          matches.add(match);
        }
      }

      // Pro ka≈æd√Ω nalezen√Ω objekt
      for (final obj in objects) {
        final match = await _matchObjectToOvce(obj, image);
        if (match != null) {
          matches.add(match);
        }
      }

      // Odstranƒõn√≠ duplicit a se≈ôazen√≠ podle confidence
      final uniqueMatches = _removeDuplicateMatches(matches);
      uniqueMatches.sort((a, b) => b.confidence.compareTo(a.confidence));

      print('‚úÖ Celkem nalezeno ${uniqueMatches.length} jedineƒçn√Ωch shod s datab√°z√≠');
      return uniqueMatches.take(3).toList(); // Maxim√°lnƒõ 3 nejlep≈°√≠ shody

    } catch (e) {
      print('‚ùå Chyba p≈ôi rozpozn√°v√°n√≠: $e');
      return [];
    }
  }

  /// Rozpozn√° text v obraze a pokus√≠ se naj√≠t u≈°n√≠ ƒç√≠sla ovc√≠
  Future<List<OvceMatch>> _matchTextToOvce(RecognizedText recognizedText) async {
    final matches = <OvceMatch>[];
    
    for (final block in recognizedText.blocks) {
      for (final line in block.lines) {
        for (final element in line.elements) {
          final text = element.text.trim();
          
          // Hled√°me ƒç√≠sla (u≈°n√≠ znaƒçky)
          if (RegExp(r'^\d{3,6}$').hasMatch(text)) {
            final matchedOvce = _referenceOvce.where((ovce) => 
              ovce.usiCislo.contains(text) || text.contains(ovce.usiCislo)
            ).firstOrNull;
            
            if (matchedOvce != null) {
              matches.add(OvceMatch(
                ovce: matchedOvce,
                confidence: 0.95, // Vysok√° confidence pro p≈ôesnou shodu textu
                boundingBox: element.boundingBox,
              ));
              print('üéØ TEXT SHODA: ${matchedOvce.usiCislo} (text: $text)');
            }
          }
        }
      }
    }
    
    return matches;
  }

  /// Odstran√≠ duplicitn√≠ shody ze seznamu
  List<OvceMatch> _removeDuplicateMatches(List<OvceMatch> matches) {
    final seen = <String>{};
    return matches.where((match) => seen.add(match.ovce.usiCislo)).toList();
  }

  /// Porovn√° nalezen√Ω obliƒçej s datab√°z√≠ ovc√≠ pomoc√≠ biometrick√Ωch dat
  Future<OvceMatch?> _matchFaceToOvce(Face face, CameraImage image) async {
    try {
      // Filtrace ovc√≠ s biometrick√Ωmi daty
      final trainedOvce = _referenceOvce.where((ovce) => ovce.hasGoodBiometrics).toList();
      if (trainedOvce.isEmpty) {
        // Fallback na v≈°echny ovce pokud nejsou biometrick√° data
        final random = DateTime.now().millisecond % _referenceOvce.length;
        final matchedOvce = _referenceOvce[random];
        double confidence = 0.3 + (DateTime.now().millisecond % 40) / 100.0;
        
        return OvceMatch(
          ovce: matchedOvce,
          confidence: confidence,
          boundingBox: face.boundingBox,
        );
      }

      // Extrakce z√°kladn√≠ch rys≈Ø z detekovan√©ho obliƒçeje
      final detectedFeatures = await _extractFeaturesFromFace(face);
      if (detectedFeatures == null) return null;

      // Porovn√°n√≠ s ka≈ædou natr√©novanou ovc√≠
      OvceMatch? bestMatch;
      double bestConfidence = 0.0;

      for (final ovce in trainedOvce) {
        if (ovce.biometrics == null) continue;

        final similarity = detectedFeatures.compareTo(ovce.biometrics!);
        
        // Zapoƒç√≠t√°me historickou p≈ôesnost
        final adjustedConfidence = similarity * (ovce.recognitionAccuracy + 0.5) / 1.5;
        
        if (adjustedConfidence > bestConfidence && adjustedConfidence > 0.4) {
          bestConfidence = adjustedConfidence;
          bestMatch = OvceMatch(
            ovce: ovce, 
            confidence: adjustedConfidence,
            boundingBox: face.boundingBox,
          );
        }
      }

      if (bestMatch != null) {
        print('‚ú® Nalezena shoda: ${bestMatch.ovce.usiCislo} (${(bestMatch.confidence * 100).toInt()}%)');
      }

      return bestMatch;

    } catch (e) {
      print('‚ùå Chyba p≈ôi porovn√°v√°n√≠ obliƒçeje: $e');
      return null;
    }
  }

  /// Extrahuje z√°kladn√≠ biometrick√© rysy z detekovan√©ho obliƒçeje  
  Future<OvceBiometrics?> _extractFeaturesFromFace(Face face) async {
    try {
      // Vytvo≈ô√≠me jednoduch√Ω face embedding z landmarks
      List<double> faceEmbedding = List.filled(128, 0.0);
      
      // Pou≈æijeme landmarks pokud jsou dostupn√©
      if (face.landmarks.isNotEmpty) {
        int index = 0;
        for (var landmark in face.landmarks.values) {
          if (index < 126 && landmark != null) {
            faceEmbedding[index] = landmark.position.x / 1000.0;
            faceEmbedding[index + 1] = landmark.position.y / 1000.0;
            index += 2;
          }
        }
      }

      // Z√°kladn√≠ geometrick√© rozmƒõry
      final boundingBox = face.boundingBox;
      final shapeMetrics = ShapeMetrics(
        headWidth: boundingBox.width / 1000.0,
        headHeight: boundingBox.height / 1000.0,
        earLength: boundingBox.height * 0.3 / 1000.0,
        earWidth: boundingBox.width * 0.15 / 1000.0,
        muzzleWidth: boundingBox.width * 0.4 / 1000.0,
        eyeDistance: boundingBox.width * 0.6 / 1000.0,
        noseToEarRatio: 0.6,
      );

      // Z√°kladn√≠ barevn√Ω profil (pr√°zdn√Ω pro live detekci)
      final colorProfile = ColorProfile(
        dominantColor: const Color(0xFFE0E0E0),
        secondaryColor: const Color(0xFF808080),
        brightness: 0.5,
        contrast: 0.5,
      );

      return OvceBiometrics(
        usiCislo: 'live_detection',
        faceEmbedding: faceEmbedding,
        colorProfile: colorProfile,
        shapeMetrics: shapeMetrics,
        uniqueMarks: UniqueMarks(),
        lastUpdated: DateTime.now(),
        confidence: 0.7,
        trainingPhotosCount: 1,
      );

    } catch (e) {
      print('‚ùå Chyba p≈ôi extrakci rys≈Ø: $e');
      return null;
    }
  }

  /// Porovn√° nalezen√Ω objekt s datab√°z√≠ ovc√≠
  Future<OvceMatch?> _matchObjectToOvce(DetectedObject object, CameraImage image) async {
    try {
      // Filtr pouze pro relevantn√≠ objekty (zv√≠≈ôata)
      final relevantLabels = object.labels.where((label) => 
        label.text.toLowerCase().contains('animal') ||
        label.text.toLowerCase().contains('sheep') ||
        label.text.toLowerCase().contains('mammal') ||
        label.confidence > 0.6
      ).toList();

      if (relevantLabels.isEmpty || _referenceOvce.isEmpty) return null;

      // Pro objekty pou≈æ√≠v√°me n√°hodn√Ω v√Ωbƒõr
      final random = DateTime.now().millisecond % _referenceOvce.length;
      final matchedOvce = _referenceOvce[random];
      
      // Confidence zalo≈æen√° na nejlep≈°√≠m labelu
      final bestLabel = relevantLabels.first;
      double confidence = bestLabel.confidence * 0.6; // Konzervativnƒõj≈°√≠ pro objekty

      if (confidence > 0.3) {
        print('üéØ Objekt shoda: ${matchedOvce.usiCislo} (${(confidence * 100).toInt()}%)');
        return OvceMatch(
          ovce: matchedOvce,
          confidence: confidence,
          boundingBox: object.boundingBox,
        );
      }

      return null;
    } catch (e) {
      print('‚ùå Chyba p≈ôi porovn√°v√°n√≠ objektu: $e');
      return null;
    }
  }

  /// Konvertuje CameraImage na InputImage pro ML Kit
  InputImage? _convertCameraImage(CameraImage image) {
    try {
      // Opraven√° konverze pro spr√°vnou funkci ML Kit
      final WriteBuffer allBytes = WriteBuffer();
      
      // Pouze pro NV21 form√°t - pou≈æijeme prvn√≠ rovinu (Y)
      allBytes.putUint8List(image.planes[0].bytes);
      final bytes = allBytes.done().buffer.asUint8List();

      final Size imageSize = Size(image.width.toDouble(), image.height.toDouble());
      
      // Dynamick√© nastaven√≠ rotace na z√°kladƒõ platformy
      const InputImageRotation imageRotation = InputImageRotation.rotation90deg;
      const InputImageFormat inputImageFormat = InputImageFormat.nv21;

      final metadata = InputImageMetadata(
        size: imageSize,
        rotation: imageRotation,
        format: inputImageFormat,
        bytesPerRow: image.planes[0].bytesPerRow,
      );

      final inputImage = InputImage.fromBytes(
        bytes: bytes,
        metadata: metadata,
      );
      
      print('üì∏ √öspƒõ≈°nƒõ konvertov√°n obraz ${image.width}x${image.height}');
      return inputImage;
    } catch (e) {
      print('‚ùå Chyba p≈ôi konverzi CameraImage: $e');
      return null;
    }
  }

  /// Rozpozn√° ovce na statick√© fotce ze souboru
  Future<List<OvceMatch>> recognizeOvceInPhoto(String imagePath) async {
    try {
      print('üì∏ Analyzuji fotku: $imagePath');
      
      // Vytvo≈ô√≠me InputImage ze souboru
      final inputImage = InputImage.fromFilePath(imagePath);
      
      // 1. Detekce textu (u≈°n√≠ znaƒçky) - nejvy≈°≈°√≠ priorita
      final recognizedText = await _textRecognizer.processImage(inputImage);
      final textMatches = await _matchTextToOvce(recognizedText);
      print('üìù Nalezeno ${textMatches.length} textov√Ωch shod');
      
      // 2. Detekce obliƒçej≈Ø
      final faces = await _faceDetector.processImage(inputImage);
      print('üë§ Nalezeno ${faces.length} obliƒçej≈Ø');
      
      // 3. Detekce objekt≈Ø
      final objects = await _objectDetector.processImage(inputImage);
      print('üéØ Nalezeno ${objects.length} objekt≈Ø');
      
      // 4. Kombinujeme v√Ωsledky
      final matches = <OvceMatch>[];
      
      // Priorita: Text > Obliƒçeje > Objekty
      matches.addAll(textMatches);
      
      // Pro obr√°zky pou≈æ√≠v√°me jednodu≈°≈°√≠ simulaci ne≈æ pro live video
      // Mockujeme CameraImage pro kompatibilitu s existuj√≠c√≠mi metodami
      for (final face in faces) {
        // Simulujeme biometrick√© porovn√°n√≠
        if (_referenceOvce.isNotEmpty && matches.length < 3) {
          final faceArea = face.boundingBox.width * face.boundingBox.height;
          final normalizedArea = (faceArea / (1000 * 1000)).clamp(0.0, 1.0);
          
          double confidence = (normalizedArea * 0.5 + 0.3).clamp(0.3, 0.8);
          
          // V√Ωbƒõr ovce na z√°kladƒõ pozice obliƒçeje
          final centerX = face.boundingBox.center.dx;
          final index = (centerX.round()) % _referenceOvce.length;
          final matchedOvce = _referenceOvce[index];
          
          matches.add(OvceMatch(
            ovce: matchedOvce,
            confidence: confidence,
            boundingBox: face.boundingBox,
          ));
          print('üêë Face shoda: ${matchedOvce.usiCislo} (${(confidence * 100).toInt()}%)');
        }
      }
      
      // Podobnƒõ pro objekty
      for (final object in objects) {
        if (_referenceOvce.isNotEmpty && matches.length < 5) {
          // Filtrujeme jen relevantn√≠ objekty
          final relevantLabels = object.labels.where((label) => 
            ['sheep', 'animal', 'mammal', 'livestock'].any((keyword) => 
              label.text.toLowerCase().contains(keyword))
          ).toList();
          
          if (relevantLabels.isNotEmpty) {
            final bestLabel = relevantLabels.first;
            double confidence = bestLabel.confidence * 0.6;
            
            if (confidence > 0.3) {
              final index = DateTime.now().millisecond % _referenceOvce.length;
              final matchedOvce = _referenceOvce[index];
              
              matches.add(OvceMatch(
                ovce: matchedOvce,
                confidence: confidence,
                boundingBox: object.boundingBox,
              ));
              print('üéØ Object shoda: ${matchedOvce.usiCislo} (${(confidence * 100).toInt()}%)');
            }
          }
        }
      }
      
      // Odstranƒõn√≠ duplicit a se≈ôazen√≠
      final uniqueMatches = _removeDuplicateMatches(matches);
      uniqueMatches.sort((a, b) => b.confidence.compareTo(a.confidence));
      
      print('‚úÖ Celkem ${uniqueMatches.length} jedineƒçn√Ωch shod z fotky');
      return uniqueMatches.take(5).toList(); // Maxim√°lnƒõ 5 nejlep≈°√≠ch shod
      
    } catch (e) {
      print('‚ùå Chyba p≈ôi rozpozn√°v√°n√≠ z fotky: $e');
      return [];
    }
  }

  /// Uvoln√≠ zdroje
  void dispose() {
    _faceDetector.close();
    _objectDetector.close();
    _textRecognizer.close();
    _biometricExtractor.dispose();
  }
}